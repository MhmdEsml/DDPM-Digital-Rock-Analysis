{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!pip3 install diffusers"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-10T07:11:51.554733Z",
          "iopub.execute_input": "2024-04-10T07:11:51.555405Z",
          "iopub.status.idle": "2024-04-10T07:12:17.783436Z",
          "shell.execute_reply.started": "2024-04-10T07:11:51.555375Z",
          "shell.execute_reply": "2024-04-10T07:12:17.782331Z"
        },
        "trusted": true,
        "id": "6_qpfO4k36hr",
        "outputId": "1534d528-445e-4bc8-c96c-65852450c3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting gdown\n  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.13.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.1.0-py3-none-any.whl (17 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.1.0\nCollecting diffusers\n  Downloading diffusers-0.27.2-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers) (6.11.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from diffusers) (3.13.1)\nRequirement already satisfied: huggingface-hub>=0.20.2 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.22.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from diffusers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from diffusers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from diffusers) (2.31.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from diffusers) (0.4.2)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from diffusers) (9.5.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.9.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->diffusers) (2024.2.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.20.2->diffusers) (3.1.1)\nDownloading diffusers-0.27.2-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: diffusers\nSuccessfully installed diffusers-0.27.2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import gdown\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import imageio\n",
        "from PIL import Image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:12:17.785804Z",
          "iopub.execute_input": "2024-04-10T07:12:17.786553Z",
          "iopub.status.idle": "2024-04-10T07:12:21.756178Z",
          "shell.execute_reply.started": "2024-04-10T07:12:17.786513Z",
          "shell.execute_reply": "2024-04-10T07:12:21.755210Z"
        },
        "trusted": true,
        "id": "cVJjsapI36hu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    type = input(\"Please enter the type (sandstone or carbonate): \")\n",
        "    if type == 'carbonate':\n",
        "        file_id = '1eODve5OnefilLwQVpnRAHCgPcM6LyLkH'\n",
        "        break\n",
        "    elif type == 'sandstone':\n",
        "        file_id = '1rifCP9gTgoBobhMugEuhtUcMfWYTpt62'\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid type! Please choose between 'sandstone' and 'carbonate'.\")\n",
        "\n",
        "url_template = 'https://drive.google.com/uc?id={}'\n",
        "gdown.download(url_template.format(file_id), 'model.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:12:21.757251Z",
          "iopub.execute_input": "2024-04-10T07:12:21.757694Z",
          "iopub.status.idle": "2024-04-10T07:13:07.737534Z",
          "shell.execute_reply.started": "2024-04-10T07:12:21.757666Z",
          "shell.execute_reply": "2024-04-10T07:13:07.736554Z"
        },
        "trusted": true,
        "id": "WN-lY33W36hw",
        "outputId": "eb69f56e-e012-4376-d394-8604e0846460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Please enter the type (sandstone or carbonate):  carbonate\n"
        },
        {
          "name": "stderr",
          "text": "Downloading...\nFrom (original): https://drive.google.com/uc?id=1eODve5OnefilLwQVpnRAHCgPcM6LyLkH\nFrom (redirected): https://drive.google.com/uc?id=1eODve5OnefilLwQVpnRAHCgPcM6LyLkH&confirm=t&uuid=d954b082-0998-45fe-8542-f50b23233a1f\nTo: /kaggle/working/model.pth\n100%|██████████| 288M/288M [00:01<00:00, 211MB/s] \n",
          "output_type": "stream"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'model.pth'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 256\n",
        "NUM_GENERATE_IMAGES = 8\n",
        "NUM_LOOP = 1\n",
        "NUM_TIMESTEPS = 500\n",
        "MIXED_PRECISION = \"fp16\"\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:13:07.740309Z",
          "iopub.execute_input": "2024-04-10T07:13:07.740672Z",
          "iopub.status.idle": "2024-04-10T07:13:07.776164Z",
          "shell.execute_reply.started": "2024-04-10T07:13:07.740647Z",
          "shell.execute_reply": "2024-04-10T07:13:07.775305Z"
        },
        "trusted": true,
        "id": "zGfVOVnG36hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Diffusion:\n",
        "    def __init__(self, beta_start=1e-4, beta_end=0.02, timesteps=1000, clip_min=-1.0, clip_max=1.0):\n",
        "        self.beta_start = beta_start\n",
        "        self.beta_end = beta_end\n",
        "        self.timesteps = timesteps\n",
        "        self.clip_min = clip_min\n",
        "        self.clip_max = clip_max\n",
        "\n",
        "        betas = np.linspace(beta_start, beta_end, timesteps, dtype=np.float64)\n",
        "        self.num_timesteps = int(timesteps)\n",
        "\n",
        "        alphas = 1.0 - betas\n",
        "        alphas_cumprod = np.cumprod(alphas, axis=0)\n",
        "        alphas_cumprod_prev = np.append(1.0, alphas_cumprod[:-1])\n",
        "\n",
        "        self.betas = torch.tensor(betas, dtype=torch.float32, device=device)\n",
        "        self.alphas_cumprod = torch.tensor(alphas_cumprod, dtype=torch.float32, device=device)\n",
        "        self.alphas_cumprod_prev = torch.tensor(alphas_cumprod_prev, dtype=torch.float32, device=device)\n",
        "\n",
        "        self.sqrt_alphas_cumprod = torch.tensor(np.sqrt(alphas_cumprod), dtype=torch.float32, device=device)\n",
        "        self.sqrt_one_minus_alphas_cumprod = torch.tensor(np.sqrt(1.0 - alphas_cumprod), dtype=torch.float32, device=device)\n",
        "        self.log_one_minus_alphas_cumprod = torch.tensor(np.log(1.0 - alphas_cumprod), dtype=torch.float32, device=device)\n",
        "        self.sqrt_recip_alphas_cumprod = torch.tensor(np.sqrt(1.0 / alphas_cumprod), dtype=torch.float32, device=device)\n",
        "        self.sqrt_recipm1_alphas_cumprod = torch.tensor(np.sqrt(1.0 / alphas_cumprod - 1), dtype=torch.float32, device=device)\n",
        "\n",
        "        posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
        "        self.posterior_variance = torch.tensor(posterior_variance, dtype=torch.float32, device=device)\n",
        "\n",
        "        self.posterior_log_variance_clipped = torch.tensor(np.log(np.maximum(posterior_variance, 1e-20)), dtype=torch.float32, device=device)\n",
        "\n",
        "        self.posterior_mean_coef1 = torch.tensor(betas * np.sqrt(alphas_cumprod_prev) / (1.0 - alphas_cumprod), dtype=torch.float32, device=device)\n",
        "        self.posterior_mean_coef2 = torch.tensor((1.0 - alphas_cumprod_prev) * np.sqrt(alphas) / (1.0 - alphas_cumprod), dtype=torch.float32, device=device)\n",
        "\n",
        "    def _extract(self, a, t, x_shape):\n",
        "        batch_size = x_shape[0]\n",
        "        out = a[t].view(batch_size, 1, 1, 1)\n",
        "        return out\n",
        "\n",
        "    def q_mean_variance(self, x_start, t):\n",
        "        x_start_shape = x_start.shape\n",
        "        mean = self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
        "        variance = self._extract(1.0 - self.alphas_cumprod, t, x_start_shape)\n",
        "        log_variance = self._extract(self.log_one_minus_alphas_cumprod, t, x_start_shape)\n",
        "        return mean, variance, log_variance\n",
        "\n",
        "    def q_sample(self, x_start, t, noise):\n",
        "        x_start_shape = x_start.shape\n",
        "        return (\n",
        "            self._extract(self.sqrt_alphas_cumprod, t, x_start_shape) * x_start\n",
        "            + self._extract(self.sqrt_one_minus_alphas_cumprod, t, x_start_shape) * noise\n",
        "        )\n",
        "\n",
        "    def predict_start_from_noise(self, x_t, t, noise):\n",
        "        x_t_shape = x_t.shape\n",
        "        return (\n",
        "            self._extract(self.sqrt_recip_alphas_cumprod, t, x_t_shape) * x_t\n",
        "            - self._extract(self.sqrt_recipm1_alphas_cumprod, t, x_t_shape) * noise\n",
        "        )\n",
        "\n",
        "    def q_posterior(self, x_start, x_t, t):\n",
        "        x_t_shape = x_t.shape\n",
        "        posterior_mean = (\n",
        "            self._extract(self.posterior_mean_coef1, t, x_t_shape) * x_start\n",
        "            + self._extract(self.posterior_mean_coef2, t, x_t_shape) * x_t\n",
        "        )\n",
        "        posterior_variance = self._extract(self.posterior_variance, t, x_t_shape)\n",
        "        posterior_log_variance_clipped = self._extract(\n",
        "            self.posterior_log_variance_clipped, t, x_t_shape\n",
        "        )\n",
        "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
        "\n",
        "    def p_mean_variance(self, pred_noise, x, t, clip_denoised=True):\n",
        "        x_recon = self.predict_start_from_noise(x, t=t, noise=pred_noise)\n",
        "        if clip_denoised:\n",
        "            x_recon = torch.clamp(x_recon, self.clip_min, self.clip_max)\n",
        "\n",
        "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n",
        "        return model_mean, posterior_variance, posterior_log_variance\n",
        "\n",
        "    def p_sample(self, pred_noise, x, t, clip_denoised=True):\n",
        "        model_mean, _, model_log_variance = self.p_mean_variance(pred_noise, x=x, t=t, clip_denoised=clip_denoised)\n",
        "        noise = torch.randn_like(x)\n",
        "        nonzero_mask = torch.reshape(1 - (t == 0).to(torch.float32), [x.size(0), 1, 1, 1])\n",
        "        return model_mean + nonzero_mask * torch.exp(0.5 * model_log_variance) * noise\n",
        "\n",
        "gdf_util = Diffusion(timesteps=NUM_TIMESTEPS)\n",
        "\n",
        "\n",
        "def generate_images(model, step, img_size=512, img_channels=1, num_images=2, timesteps=1000):\n",
        "\n",
        "    # 1. Randomly sample noise (starting point for reverse process)\n",
        "    samples = torch.randn((num_images, img_channels, img_size, img_size), dtype=torch.float32).to(device)\n",
        "\n",
        "    # 2. Sample from the model iteratively\n",
        "    for t in tqdm(reversed(range(0, timesteps)), desc=f\"Generating images at loop {step + 1}\", total=timesteps, position=0, leave=True):\n",
        "        tt = torch.full((num_images,), t, dtype=torch.long).to(device)\n",
        "        with torch.no_grad():\n",
        "            pred_noise = model(samples, tt, return_dict=False)[0]\n",
        "\n",
        "        samples = gdf_util.p_sample(\n",
        "                pred_noise, samples, tt, clip_denoised=True\n",
        "            )\n",
        "\n",
        "    # 3. Return generated samples\n",
        "    return samples"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:13:07.777756Z",
          "iopub.execute_input": "2024-04-10T07:13:07.778128Z",
          "iopub.status.idle": "2024-04-10T07:13:07.974125Z",
          "shell.execute_reply.started": "2024-04-10T07:13:07.778097Z",
          "shell.execute_reply": "2024-04-10T07:13:07.973219Z"
        },
        "trusted": true,
        "id": "gfeHtxU436hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('./model.pth')\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:13:07.975319Z",
          "iopub.execute_input": "2024-04-10T07:13:07.975665Z",
          "iopub.status.idle": "2024-04-10T07:13:12.088860Z",
          "shell.execute_reply.started": "2024-04-10T07:13:07.975630Z",
          "shell.execute_reply": "2024-04-10T07:13:12.088043Z"
        },
        "trusted": true,
        "id": "FeoHjV6m36hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory to save the generated images\n",
        "if not os.path.exists('./Generated_images'):\n",
        "    os.makedirs('./Generated_images')\n",
        "\n",
        "for j in tqdm(range(NUM_LOOP), position=0, leave=True):\n",
        "    images = generate_images(model, j, img_size=IMG_SIZE, img_channels=1, num_images=NUM_GENERATE_IMAGES, timesteps=NUM_TIMESTEPS)\n",
        "\n",
        "    images_processed = (images.cpu().numpy() * 127.5 + 127.5).round().astype(\"uint8\")\n",
        "\n",
        "    for i in range(1, NUM_GENERATE_IMAGES + 1):\n",
        "        # Save each generated image as a PNG file\n",
        "        image_to_save = np.squeeze(images_processed[i-1])\n",
        "        image_to_save = Image.fromarray(image_to_save, mode='L')\n",
        "\n",
        "        image_path = os.path.join(f'./Generated_images', f'generated_image_{i + j * NUM_GENERATE_IMAGES:04d}.png')\n",
        "        imageio.imwrite(image_path, np.array(image_to_save))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:13:12.090039Z",
          "iopub.execute_input": "2024-04-10T07:13:12.090487Z",
          "iopub.status.idle": "2024-04-10T07:14:29.683671Z",
          "shell.execute_reply.started": "2024-04-10T07:13:12.090461Z",
          "shell.execute_reply": "2024-04-10T07:14:29.682788Z"
        },
        "trusted": true,
        "id": "T2b2faYo36hz",
        "outputId": "89a18848-feb6-4743-caf6-2e7eb18d5444"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Generating images at loop 1: 100%|██████████| 500/500 [01:17<00:00,  6.47it/s]\n100%|██████████| 1/1 [01:17<00:00, 77.58s/it]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r ./Generated_images.zip ./Generated_images"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-10T07:14:29.684834Z",
          "iopub.execute_input": "2024-04-10T07:14:29.685130Z",
          "iopub.status.idle": "2024-04-10T07:14:30.656953Z",
          "shell.execute_reply.started": "2024-04-10T07:14:29.685105Z",
          "shell.execute_reply": "2024-04-10T07:14:30.656011Z"
        },
        "trusted": true,
        "id": "OfbYLa4736h0",
        "outputId": "f14df337-8774-439c-91d3-e02b43d7ba3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "  adding: Generated_images/ (stored 0%)\n  adding: Generated_images/generated_image_0004.png (deflated 0%)\n  adding: Generated_images/generated_image_0006.png (deflated 0%)\n  adding: Generated_images/generated_image_0003.png (deflated 0%)\n  adding: Generated_images/generated_image_0008.png (deflated 0%)\n  adding: Generated_images/generated_image_0002.png (deflated 0%)\n  adding: Generated_images/generated_image_0001.png (deflated 0%)\n  adding: Generated_images/generated_image_0007.png (deflated 0%)\n  adding: Generated_images/generated_image_0005.png (deflated 0%)\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}